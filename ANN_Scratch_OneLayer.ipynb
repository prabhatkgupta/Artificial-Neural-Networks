{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Scratch_OneLayer",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcdx5nOZBvBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCE5DfenrR5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('drive/My Drive/Dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knifzu7aPmL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Load_Data():\n",
        "  \n",
        "  train_set = h5py.File('train_catvnoncat.h5','r')\n",
        "  train_set_X_orig = np.array(train_set['train_set_x'][:])\n",
        "  train_set_Y_orig = np.array(train_set['train_set_y'][:])\n",
        "  \n",
        "  test_set = h5py.File('test_catvnoncat.h5')\n",
        "  test_set_X_orig = np.array(test_set['test_set_x'][:])\n",
        "  test_set_Y_orig = np.array(test_set['test_set_y'][:])\n",
        "  classes = np.array(test_set['list_classes'][:])\n",
        "  \n",
        "  return train_set_X_orig,train_set_Y_orig,test_set_X_orig,test_set_Y_orig,classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK3qzxRkc33M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Reshape_And_Normalize(train_set_X_orig,train_set_Y_orig,test_set_X_orig,test_set_Y_orig):\n",
        "  \n",
        "  train_set_X = train_set_X_orig.reshape(train_set_X_orig.shape[0],-1).T\n",
        "  test_set_X = test_set_X_orig.reshape(test_set_X_orig.shape[0],-1).T\n",
        "  train_set_Y = train_set_Y_orig.reshape(1,train_set_Y_orig.shape[0])\n",
        "  test_set_Y = test_set_Y_orig.reshape(1,test_set_Y_orig.shape[0])\n",
        "  \n",
        "  m_train = train_set_X.shape[1]\n",
        "  m_test = test_set_X.shape[1]\n",
        "  \n",
        "  U_train = np.sum(train_set_X,axis=0,keepdims=True)/train_set_X.shape[0]\n",
        "  U_test = np.sum(test_set_X,axis=0,keepdims=True)/test_set_X.shape[0]\n",
        "  train_set_X = train_set_X - U_train\n",
        "  test_set_X = test_set_X - U_test\n",
        "  \n",
        "  sigma_train = np.sqrt(np.sum(np.square(train_set_X),axis=0,keepdims=True)/train_set_X.shape[0])\n",
        "  sigma_test = np.sqrt(np.sum(np.square(test_set_X),axis=0,keepdims=True)/test_set_X.shape[0])\n",
        "  \n",
        "  train_set_X = train_set_X/sigma_train\n",
        "  test_set_X = test_set_X/sigma_test\n",
        "  \n",
        "  assert(sigma_train.shape == (1,m_train) and train_set_Y.shape == (1,m_train))\n",
        "  \n",
        "  return train_set_X,train_set_Y,test_set_X,test_set_Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYd2LvtHapg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Data_Preprocessing():\n",
        "  \n",
        "  train_set_X,train_set_Y,test_set_X,test_set_Y,classes = Load_Data()\n",
        "  #plt.imshow(train_set_X[0])\n",
        "  print(\"y = \"+str(train_set_Y[0])+\". It is a \"+classes[train_set_Y[0]].decode('utf-8')+' picture')\n",
        "  train_set_X,train_set_Y,test_set_X,test_set_Y = Reshape_And_Normalize(train_set_X,train_set_Y,test_set_X,test_set_Y)\n",
        "  \n",
        "  return train_set_X,train_set_Y,test_set_X,test_set_Y,classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-319oBfhvLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Initialize_Parameters(train_set_X,output_neurons):\n",
        "  \n",
        "  parameters={}\n",
        "  W = np.random.randn(output_neurons,train_set_X.shape[0])*np.sqrt(1/train_set_X.shape[0])\n",
        "  b = np.zeros((output_neurons,1))\n",
        "  Y = np.random.randn(output_neurons,1)*np.sqrt(1/train_set_X.shape[0])\n",
        "  B = np.zeros((output_neurons,1))\n",
        "  \n",
        "  parameters['W'] = W \n",
        "  parameters['b'] = b\n",
        "  parameters['Y'] = Y\n",
        "  parameters['B'] = B\n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRuXxiIr0RV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Initialize_Optimizer(parameters):\n",
        "  \n",
        "  v = {} \n",
        "  s = {}\n",
        "  dW = np.zeros(parameters['W'].shape)\n",
        "  db = np.zeros(parameters['b'].shape)\n",
        "  dY = np.zeros(parameters['Y'].shape)\n",
        "  dB = np.zeros(parameters['B'].shape)\n",
        "  \n",
        "  s['dW'] = v['dW'] = dW\n",
        "  s['db'] = v['db'] = db\n",
        "  s['dY'] = v['dY'] = dY\n",
        "  s['dB'] = v['dB'] = dB\n",
        "  \n",
        "  return v,s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iloKbdBctxes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "  \n",
        "  A = 1/(1+np.exp(-Z))\n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRs8yqhOuGM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(Z):\n",
        "  \n",
        "  exp = np.exp(Z)\n",
        "  expnorm = np.sum(exp,axis=0,keepdims=True)\n",
        "  A = exp/expnorm\n",
        "  assert(expnorm.shape == (1,exp.shape[1]))\n",
        "  \n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIKw9RnuvxBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost_sigmoid(train_set_Y,A,W,regu,lambd):\n",
        "  \n",
        "  m_train = train_set_Y.shape[1]\n",
        "  cost = np.sum(train_set_Y*np.log(A))+np.sum((1-train_set_Y)*np.log(1-A))\n",
        "  cost = -cost\n",
        "  if(regu):\n",
        "    sum = np.sum(np.square(W))*(lambd*0.5/m_train)\n",
        "    cost = cost + sum\n",
        "  \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i01EPMTCvwoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost_softmax(train_set_Y,A,W,regu,lambd):\n",
        "  \n",
        "  m_train = train_set_Y.shape[1]\n",
        "  cost = np.sum(train_set_Y,np.log(A))\n",
        "  \n",
        "  if(regu):\n",
        "    sum = np.sum(np.square(W))*(lambd*0.5/m_train)\n",
        "    cost = cost + sum\n",
        "   \n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuFZ_kbIni50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Propagation(train_set_X,train_set_Y,parameters,activation,regu,lambd):\n",
        "  \n",
        "  m_train = train_set_X.shape[1]\n",
        "  W = parameters['W']\n",
        "  b = parameters['b']\n",
        "  Y = parameters['Y']\n",
        "  B = parameters['B']\n",
        "  \n",
        "  Z = np.dot(W,train_set_X)+b\n",
        "  mu = np.sum(Z,axis=1,keepdims=True)/m_train\n",
        "  Z_minus_mu = Z - mu\n",
        "  sigma = np.sqrt(np.sum(np.square(Z_minus_mu),axis=1,keepdims=True)/m_train)\n",
        "  ZNorm = Z_minus_mu/sigma\n",
        "  Zcap = Y * ZNorm + B\n",
        "  \n",
        "  if(activation == 'sigmoid'):\n",
        "    A = sigmoid(Zcap)\n",
        "    cost = compute_cost_sigmoid(train_set_Y,A,W,regu,lambd)\n",
        "  elif(activation == 'softmax'):\n",
        "    A = softmax(Zcap)\n",
        "    cost = compute_cost_softmax(train_set_Y,A,W,regu,lambd)\n",
        "    \n",
        "    \n",
        "  grads = {}\n",
        "  dZcap = A-train_set_Y\n",
        "  dZNorm = Y * dZcap\n",
        "  dZ = dZNorm/sigma\n",
        "  dY = np.sum(dZcap * ZNorm,axis=1,keepdims=True)/m_train\n",
        "  dB = np.sum(dZcap,axis=1,keepdims=True)/m_train\n",
        "  dW = np.dot(dZ,train_set_X.T)/m_train\n",
        "  if(regu):\n",
        "    dW = dW + W*lambd/m_train\n",
        "  db = np.sum(dZ,axis=1,keepdims=True)/m_train\n",
        "  \n",
        "  grads['dW'] = dW\n",
        "  grads['db'] = db\n",
        "  grads['dY'] = dY\n",
        "  grads['dB'] = dB\n",
        "  \n",
        "  assert(db.shape == b.shape and dW.shape == W.shape)\n",
        "  \n",
        "  return grads,mu,sigma,cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u36RQw2T3l8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Shuffle_And_Split(train_set_X,train_set_Y,mini_batch_size):\n",
        "  \n",
        "  m_train = train_set_X.shape[1]\n",
        "  perm = list(np.random.permutation(train_set_X.shape[1]))\n",
        "  train_set_X = train_set_X[:,perm]\n",
        "  train_set_Y = train_set_Y[:,perm]\n",
        "  \n",
        "  n = int(m_train/mini_batch_size)\n",
        "  minibatches = []\n",
        "  \n",
        "  for i in range(n):\n",
        "    X = train_set_X[:,i*mini_batch_size:(i+1)*mini_batch_size]\n",
        "    Y = train_set_Y[:,i*mini_batch_size:(i+1)*mini_batch_size]\n",
        "    minibatch = (X,Y)\n",
        "    minibatches.append(minibatch)\n",
        "  \n",
        "  if(m_train % mini_batch_size != 0):\n",
        "    X = train_set_X[:,n*mini_batch_size:m_train]\n",
        "    Y = train_set_Y[:,n*mini_batch_size:m_train]\n",
        "    minibatch = (X,Y)\n",
        "    minibatches.append(minibatch)\n",
        "  \n",
        "  return minibatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNGgeQkXO6mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Update_Parameters(grads,parameters,learning_rate,v,s,beta1,beta2,t,epsilon=1e-8):\n",
        "  \n",
        "  t = t+1\n",
        "  v['dW'] = beta1*v['dW'] + (1-beta1)*grads['dW']\n",
        "  vdW_corr = v['dW']/(1-(beta1**t))\n",
        "  v['db'] = beta1*v['db'] + (1-beta1)*grads['db'] \n",
        "  vdb_corr = v['db']/(1-(beta1**t))\n",
        "  v['dY'] = beta1*v['dY'] + (1-beta1)*grads['dY']\n",
        "  vdY_corr = v['dY']/(1-(beta1**t))\n",
        "  v['dB'] = beta1*v['dB'] + (1-beta1)*grads['dB']\n",
        "  vdB_corr = v['dB']/(1-(beta1**t))\n",
        "  \n",
        "  s['dW'] = beta2*s['dW'] + (1-beta2)*(grads['dW']**2)\n",
        "  sdW_corr = s['dW']/(1-(beta2**t))\n",
        "  s['db'] = beta2*s['db'] + (1-beta2)*(grads['db']**2)\n",
        "  sdb_corr = s['db']/(1-(beta2**t))\n",
        "  s['dY'] = beta2*s['dY'] + (1-beta2)*(grads['dY']**2)\n",
        "  sdY_corr = s['dY']/(1-(beta2**t))\n",
        "  s['dB'] = beta2*s['dB'] + (1-beta2)*(grads['dB']**2)\n",
        "  sdB_corr = s['dB']/(1-(beta2**t))\n",
        "  \n",
        "  parameters['W'] = parameters['W'] - learning_rate*vdW_corr/(np.sqrt(sdW_corr)+epsilon)\n",
        "  parameters['b'] = parameters['b'] - learning_rate*vdb_corr/(np.sqrt(sdb_corr)+epsilon)\n",
        "  parameters['Y'] = parameters['Y'] - learning_rate*vdY_corr/(np.sqrt(sdY_corr)+epsilon)\n",
        "  parameters['B'] = parameters['B'] - learning_rate*vdB_corr/(np.sqrt(sdB_corr)+epsilon)\n",
        "  \n",
        "  return parameters,v,s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-pjMbCof1iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dictionary_to_vector(parameters):\n",
        "  \n",
        "  res = np.array([])\n",
        "  for items in parameters:\n",
        "    items = parameters[items]\n",
        "    shape = items.shape\n",
        "    items = np.reshape(items,shape[0]*shape[1])\n",
        "    res = np.append(res,items)\n",
        "    \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDGXZzQ0f0o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vector_to_dictionary(J,param):\n",
        "  \n",
        "  parameters = {}\n",
        "  j = 0\n",
        "  for key,value in param.items():\n",
        "    shape = value.shape\n",
        "    size = shape[0]*shape[1]\n",
        "    temp = J[j:j+size]\n",
        "    j = j+size\n",
        "    temp = np.reshape(temp,shape)\n",
        "    parameters[key] = temp\n",
        " \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6THhhOIdle6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Gradient_Checking_Helper(J,X,Y,param,activation,regu,lambd):\n",
        "  \n",
        "  parameters = vector_to_dictionary(J,param)\n",
        "    \n",
        "  m_train = X.shape[1]  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b'] \n",
        "  Y = parameters['Y']\n",
        "  B = parameters['B']\n",
        "  \n",
        "  Z = np.dot(W,X)+b\n",
        "  mu = np.sum(Z,axis=1,keepdims=True)/m_train\n",
        "  Z_minus_mu = Z - mu\n",
        "  sigma = np.sqrt(np.sum(np.square(Z_minus_mu),axis=1,keepdims=True)/m_train)\n",
        "  ZNorm = Z_minus_mu/sigma\n",
        "  Zcap = Y * ZNorm + B\n",
        "  \n",
        "  if(activation == 'sigmoid'):\n",
        "    A = sigmoid(Zcap)\n",
        "    cost = compute_cost_sigmoid(Y,A,W,regu,lambd)\n",
        "  elif(activation == 'softmax'):\n",
        "    A = softmax(Zcap)\n",
        "    cost = compute_cost_softmax(Y,A,W,regu,lambd)\n",
        "    \n",
        "  return cost\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZu4zDcTJLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Gradient_Checking(grads,parameters,X,Y,activation,regu,lambd,epsilon=1e-7):\n",
        " \n",
        "  J = dictionary_to_vector(parameters)\n",
        "  G_out = dictionary_to_vector(grads)\n",
        "  m = len(J)\n",
        "  J_out = np.zeros(m)\n",
        "  \n",
        "  for i in range(m):\n",
        "    J_plus = np.copy(J)\n",
        "    J_plus[i] = J_plus[i]+epsilon\n",
        "    cost1 = Gradient_Checking_Helper(J_plus,X,Y,parameters,activation,regu,lambd)\n",
        "    \n",
        "    J_minus = np.copy(J)\n",
        "    J_minus[i] = J_minus[i]-epsilon\n",
        "    cost2 = Gradient_Checking_Helper(J_minus,X,Y,parameters,activation,regu,lambd)\n",
        "    \n",
        "    #print(J,J_plus,J_minus)\n",
        "    J_out[i] = (cost1-cost2)/(2*epsilon)\n",
        " \n",
        "  dis = np.linalg.norm(J_out-G_out)/(np.linalg.norm(J_out)+np.linalg.norm(G_out))\n",
        "  \n",
        "  return dis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvkidZYvjkps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Predict(X,parameters,activation):\n",
        "  \n",
        "  W = parameters['W']\n",
        "  b = parameters['b'] \n",
        "  Y = parameters['Y']\n",
        "  B = parameters['B']\n",
        "  \n",
        "  m = X.shape[1]\n",
        "  Z = np.dot(W,X)+b\n",
        "  mu = np.sum(Z,axis=1,keepdims=True)/m\n",
        "  Z_minus_mu = Z - mu\n",
        "  sigma = np.sqrt(np.sum(np.square(Z_minus_mu),axis=1,keepdims=True)/m)\n",
        "  ZNorm = Z_minus_mu/sigma\n",
        "  Zcap = Y*ZNorm + B\n",
        "  \n",
        "  if(activation == 'sigmoid'):\n",
        "    A = sigmoid(Zcap)\n",
        "    A = np.abs(np.ceil(A-0.5))\n",
        "    A = A.astype('int32')\n",
        "  elif(activation == 'softmax'):\n",
        "    A = softmax(Zcap)\n",
        "    A = np.argmax(A,axis=0)\n",
        "    A = np.eye(6)[A]\n",
        "   \n",
        "  return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rG824nayy4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Model(train_set_X,train_set_Y,test_set_X,test_set_Y,learning_rate,epochs,output_neurons,mini_batch_size):\n",
        "  \n",
        "  beta1 = 0.8\n",
        "  beta2 = 0.9\n",
        "  beta3 = 0.99\n",
        "  lambd = 0.005\n",
        "  activation = 'sigmoid'\n",
        "  regu = True\n",
        "  \n",
        "  if(activation == 'softmax'):\n",
        "    train_set_Y = np.eye(6)[train_set_Y]\n",
        "    test_set_Y = np.eye(6)[test_set_Y]\n",
        "    \n",
        "  total_cost = []\n",
        "  parameters = Initialize_Parameters(train_set_X,output_neurons)\n",
        "  v,s = Initialize_Optimizer(parameters)\n",
        "  u = np.zeros((output_neurons,1))\n",
        "  sig = np.zeros((output_neurons,1))\n",
        "  \n",
        "  for i in range(epochs):\n",
        "    minibatches = Shuffle_And_Split(train_set_X,train_set_Y,mini_batch_size)\n",
        "    for minibatch in minibatches:\n",
        "      (X,Y) = minibatch\n",
        "      grads,mu,sigma,cost = Propagation(X,Y,parameters,activation,regu,lambd)\n",
        "      u = beta1*u + (1-beta1)*mu\n",
        "      sig = beta1*sig + (1-beta1)*sigma\n",
        "      \n",
        "      if (i % 1000 == 0):\n",
        "        flag=Gradient_Checking(grads,parameters,X,Y,activation,regu,lambd)\n",
        "        print(\"Result of Gradient Checking : \"+str(flag))\n",
        "        \n",
        "      if(i % 10 == 0):\n",
        "        total_cost.append(cost)\n",
        "        \n",
        "      if(i % 50 == 0):\n",
        "        print('Cost after '+str(i)+'th Iteration : '+str(cost))\n",
        "      \n",
        "      parameters,v,s = Update_Parameters(grads,parameters,learning_rate,v,s,beta2,beta3,i)\n",
        "  \n",
        "  A_train = Predict(train_set_X,parameters,activation)\n",
        "  A_test = Predict(test_set_X,parameters,activation)\n",
        "  \n",
        "  if(activation == 'sigmoid'):\n",
        "    train_acc = 100-np.mean(np.abs(train_set_Y-A_train))*100\n",
        "    test_acc = 100-np.mean(np.abs(test_set_Y-A_test))*100\n",
        "    \n",
        "  elif(activation == 'softmax'):\n",
        "    train_temp = np.equal(np.argmax(A_train),np.argmax(train_set_Y))\n",
        "    train_acc = np.mean(train_temp.astype('int32'))\n",
        "    test_temp = np.equal(np.argmax(A_test),np.argmax(test_set_Y))\n",
        "    test_acc = np.mean(test_temp.astype('int32'))\n",
        "  \n",
        "  print(\"Training Set Accuracy : \"+str(train_acc))\n",
        "  print(\"Test Set Accuracy : \"+str(test_acc))\n",
        "  \n",
        "  plt.plot(total_cost)\n",
        "  plt.xlabel('Iterations')\n",
        "  plt.ylabel('Cost')\n",
        "  plt.title(\"Learning_Rate : \"+str(learning_rate))\n",
        "  plt.show()  \n",
        "  \n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YttkNLkXh3Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Caller_Function():\n",
        "  \n",
        "  train_set_X,train_set_Y,test_set_X,test_set_Y,classes = Data_Preprocessing()\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1000\n",
        "  mini_batch_size = 32\n",
        "  output_neurons = 1\n",
        "  parameters = Model(train_set_X,train_set_Y,test_set_X,test_set_Y,learning_rate,epochs,output_neurons,mini_batch_size)\n",
        "  \n",
        "  for key,value in parameters.items():\n",
        "    print(key,value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRbiV5L8nagG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02d0c433-dae7-4a9e-b598-09cf9d8e8d83"
      },
      "source": [
        "Caller_Function()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 0. It is a non-cat picture\n",
            "Result of Gradient Checking : 0.9743991555778564\n",
            "Cost after 0th Iteration : 22.165281888079978\n",
            "Result of Gradient Checking : 0.970625442603922\n",
            "Cost after 0th Iteration : 22.108473045856986\n",
            "Result of Gradient Checking : 0.968139287622383\n",
            "Cost after 0th Iteration : 22.201733265887405\n",
            "Result of Gradient Checking : 0.9803892688543225\n",
            "Cost after 0th Iteration : 22.111349455189544\n",
            "Result of Gradient Checking : 0.9842144621692328\n",
            "Cost after 0th Iteration : 22.1375240116449\n",
            "Result of Gradient Checking : 0.9884653340104572\n",
            "Cost after 0th Iteration : 22.171265645445335\n",
            "Result of Gradient Checking : 0.9786024211478094\n",
            "Cost after 0th Iteration : 11.759615317487416\n",
            "Cost after 50th Iteration : 20.219168636803794\n",
            "Cost after 50th Iteration : 20.628961875356385\n",
            "Cost after 50th Iteration : 21.153496334660854\n",
            "Cost after 50th Iteration : 20.680459583380948\n",
            "Cost after 50th Iteration : 19.608900469206528\n",
            "Cost after 50th Iteration : 20.063016636163\n",
            "Cost after 50th Iteration : 10.807450623981813\n",
            "Cost after 100th Iteration : 20.003043386005288\n",
            "Cost after 100th Iteration : 20.495074307548183\n",
            "Cost after 100th Iteration : 18.243044681199304\n",
            "Cost after 100th Iteration : 18.615061034838682\n",
            "Cost after 100th Iteration : 18.189517442328658\n",
            "Cost after 100th Iteration : 19.357218142413576\n",
            "Cost after 100th Iteration : 8.989454044207546\n",
            "Cost after 150th Iteration : 15.726996300128498\n",
            "Cost after 150th Iteration : 18.919317577048947\n",
            "Cost after 150th Iteration : 18.958842989907193\n",
            "Cost after 150th Iteration : 16.27023083436673\n",
            "Cost after 150th Iteration : 17.500279371848997\n",
            "Cost after 150th Iteration : 16.050369559496705\n",
            "Cost after 150th Iteration : 7.803971848665269\n",
            "Cost after 200th Iteration : 14.134620456765818\n",
            "Cost after 200th Iteration : 17.369064523494632\n",
            "Cost after 200th Iteration : 14.99278807229493\n",
            "Cost after 200th Iteration : 17.457479125586932\n",
            "Cost after 200th Iteration : 13.689866854626652\n",
            "Cost after 200th Iteration : 14.361362593537681\n",
            "Cost after 200th Iteration : 8.22150066508652\n",
            "Cost after 250th Iteration : 13.029597074561554\n",
            "Cost after 250th Iteration : 11.577493428026418\n",
            "Cost after 250th Iteration : 16.816616293955448\n",
            "Cost after 250th Iteration : 10.392758451500232\n",
            "Cost after 250th Iteration : 10.750093495386748\n",
            "Cost after 250th Iteration : 14.478123203172215\n",
            "Cost after 250th Iteration : 6.190886224787791\n",
            "Cost after 300th Iteration : 9.425970714827626\n",
            "Cost after 300th Iteration : 12.036622649744379\n",
            "Cost after 300th Iteration : 9.722196427350731\n",
            "Cost after 300th Iteration : 9.674909490405662\n",
            "Cost after 300th Iteration : 11.987838334872263\n",
            "Cost after 300th Iteration : 9.46340359000243\n",
            "Cost after 300th Iteration : 4.064588218765435\n",
            "Cost after 350th Iteration : 8.020645468059127\n",
            "Cost after 350th Iteration : 7.914729144717147\n",
            "Cost after 350th Iteration : 6.9831326778154175\n",
            "Cost after 350th Iteration : 8.484553017235493\n",
            "Cost after 350th Iteration : 8.654323102622522\n",
            "Cost after 350th Iteration : 6.368052225540526\n",
            "Cost after 350th Iteration : 3.94906626109458\n",
            "Cost after 400th Iteration : 5.69330912100751\n",
            "Cost after 400th Iteration : 6.1175409344861365\n",
            "Cost after 400th Iteration : 6.204529712879988\n",
            "Cost after 400th Iteration : 6.427976919946624\n",
            "Cost after 400th Iteration : 5.835426854809184\n",
            "Cost after 400th Iteration : 7.273302595776351\n",
            "Cost after 400th Iteration : 2.7547674438976695\n",
            "Cost after 450th Iteration : 3.586885594725745\n",
            "Cost after 450th Iteration : 6.090038688617092\n",
            "Cost after 450th Iteration : 5.2686105710896065\n",
            "Cost after 450th Iteration : 5.253344280193159\n",
            "Cost after 450th Iteration : 4.856634074407002\n",
            "Cost after 450th Iteration : 7.050859514350502\n",
            "Cost after 450th Iteration : 2.291545022522382\n",
            "Cost after 500th Iteration : 3.6097448425715633\n",
            "Cost after 500th Iteration : 3.6405220441938093\n",
            "Cost after 500th Iteration : 3.7103580455701985\n",
            "Cost after 500th Iteration : 3.372882322783499\n",
            "Cost after 500th Iteration : 5.791636317377632\n",
            "Cost after 500th Iteration : 3.898665634574861\n",
            "Cost after 500th Iteration : 2.423373477009455\n",
            "Cost after 550th Iteration : 2.9981876886490193\n",
            "Cost after 550th Iteration : 3.9141315664781757\n",
            "Cost after 550th Iteration : 2.8655580073811446\n",
            "Cost after 550th Iteration : 6.385943320367558\n",
            "Cost after 550th Iteration : 2.566710932909798\n",
            "Cost after 550th Iteration : 2.8582437187894185\n",
            "Cost after 550th Iteration : 3.0307286748828512\n",
            "Cost after 600th Iteration : 2.5830412939241847\n",
            "Cost after 600th Iteration : 2.097188051121322\n",
            "Cost after 600th Iteration : 2.2774068422791416\n",
            "Cost after 600th Iteration : 3.74343801719482\n",
            "Cost after 600th Iteration : 1.8835827318695495\n",
            "Cost after 600th Iteration : 5.232284603272652\n",
            "Cost after 600th Iteration : 0.9778145910644419\n",
            "Cost after 650th Iteration : 3.9472614225183853\n",
            "Cost after 650th Iteration : 3.3393716575078325\n",
            "Cost after 650th Iteration : 1.6524953918256213\n",
            "Cost after 650th Iteration : 1.5188378211156928\n",
            "Cost after 650th Iteration : 1.3733519204485298\n",
            "Cost after 650th Iteration : 2.0526896688634273\n",
            "Cost after 650th Iteration : 1.2050260953764764\n",
            "Cost after 700th Iteration : 1.829924570684199\n",
            "Cost after 700th Iteration : 2.6723065363921217\n",
            "Cost after 700th Iteration : 1.4877566666500486\n",
            "Cost after 700th Iteration : 1.035350824310204\n",
            "Cost after 700th Iteration : 2.267759841498545\n",
            "Cost after 700th Iteration : 1.3104017343098109\n",
            "Cost after 700th Iteration : 5.301932221078992\n",
            "Cost after 750th Iteration : 0.8684027031919619\n",
            "Cost after 750th Iteration : 0.903137250398694\n",
            "Cost after 750th Iteration : 1.1255257231317515\n",
            "Cost after 750th Iteration : 1.3627453452108953\n",
            "Cost after 750th Iteration : 1.1950714861548413\n",
            "Cost after 750th Iteration : 0.9410201851256278\n",
            "Cost after 750th Iteration : 1.1578191528715922\n",
            "Cost after 800th Iteration : 1.163080286408377\n",
            "Cost after 800th Iteration : 1.3053417324485488\n",
            "Cost after 800th Iteration : 0.7521367498859897\n",
            "Cost after 800th Iteration : 1.2070859653006603\n",
            "Cost after 800th Iteration : 1.191586694074233\n",
            "Cost after 800th Iteration : 1.3991130782162684\n",
            "Cost after 800th Iteration : 3.3741425257566937\n",
            "Cost after 850th Iteration : 0.4972963934914334\n",
            "Cost after 850th Iteration : 0.8545158578621236\n",
            "Cost after 850th Iteration : 1.0320834729274728\n",
            "Cost after 850th Iteration : 0.6418261603905024\n",
            "Cost after 850th Iteration : 0.9462106427721234\n",
            "Cost after 850th Iteration : 0.666153090579829\n",
            "Cost after 850th Iteration : 0.44555047404046244\n",
            "Cost after 900th Iteration : 0.8545741089000616\n",
            "Cost after 900th Iteration : 0.4459256078413024\n",
            "Cost after 900th Iteration : 1.304503334852528\n",
            "Cost after 900th Iteration : 1.1378584341834455\n",
            "Cost after 900th Iteration : 0.6679116572522046\n",
            "Cost after 900th Iteration : 0.611497174260071\n",
            "Cost after 900th Iteration : 0.7830471225951638\n",
            "Cost after 950th Iteration : 1.038736070896932\n",
            "Cost after 950th Iteration : 0.5042061402617962\n",
            "Cost after 950th Iteration : 1.1172904957307366\n",
            "Cost after 950th Iteration : 0.6019307124179663\n",
            "Cost after 950th Iteration : 0.8687591302958311\n",
            "Cost after 950th Iteration : 0.519209573199486\n",
            "Cost after 950th Iteration : 0.351929094881968\n",
            "Training Set Accuracy : 100.0\n",
            "Test Set Accuracy : 64.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXmYHFXVh3+ne/bJMlkmIfueQCAk\nhBACBAiyo4ACKgISlg8EQQVBDSoYBRVFBBRl36KAUQQSSdgJAUJISEL2hezrJJlsM5PZu/t8f9TS\nt6rrdlfPTM90T5/3eeZJLbeqTg3DPXXWS8wMQRAEIXsJtLUAgiAIQtsiikAQBCHLEUUgCIKQ5Ygi\nEARByHJEEQiCIGQ5oggEQRCyHFEEQsZDRG8S0eS2lkMQMhVRBEKTIaItRHRWW8vBzOcz8wupuj8R\nDSQiJqLD5s8WIpqSxPXXENEnqZLPfMbtRLSbiCqJ6Fkiyo8z9kwiWktENUQ0h4gGKOfyzesrzfv9\nWDmXR0SvmO/PRDQple8ktB6iCIS0hohy2loGhRJm7gDgMgB3E9HZbS0QABDRuQCmADgTwAAAgwH8\nWjO2O4BXAdwNoCuARQCmK0OmAhhm3ucMAD8lovOU858AuArA7hZ9CaFNEUUgpAQi+hoRLSWiQ0T0\nKREdq5ybQkQbiaiKiFYT0TeUc9cQ0TwieoiI9gOYan1RE9GfiOggEW0movOVaz4kov9Tro83dhAR\nfWQ++z0i+hsR/TOZd2PmRQBWARiT6J2I6CgAjwM4ybQmDpnH800ZtxHRHiJ6nIgKk/w1W0wG8Awz\nr2LmgwDuBXCNZuwlAFYx83+YuQ7GxD+aiI5U7nUvMx9k5jUAnrLuxcwNzPwwM38CINxEWYU0RBSB\n0OIQ0XEAngXwPQDdADwBYKbirtgI4FQAnWF8uf6TiHoptzgRwCYAPQH8Vjm2DkB3AH8E8AwRkUaE\neGNfArDQlGsqgO824f0mADgGwAblsOc7mZPpTQDmM3MHZi4xx98PYDgMZTIUQB8A92ie199UqP01\nIh0NYJmyvwxATyLqlmgsM1ebsh9NRF0A9PK419Ga5wrtBFEEQiq4EcATzLyAmcOm/74ewAQAML9G\ndzFzhJmnA1gPYLxy/S5m/iszh5i51jy2lZmfYuYwgBdgTFg9Nc/3HGtOpCcAuMf8uv0EwMwk3msf\nEdUCmA/g7wBet074eCcbUyndCOB2Zj7AzFUAfgfgcq/xzLyNmUuYeZtGrg4AKpR9a7ujj7HW+I7m\nOSD2Xl73EdoR6eR/FdoPAwBMJqIfKMfyAPQGACK6GsCPAQw0z3WA8fVusd3jnrZPmplrzA/8Dh7j\n4o3tDuAAM9e4ntUv4RsZdAfAAH4E4AoAuQAafL6TSimAIgCLFaOGAAR9yuHmMIBOyr61XeVjrDW+\nyjxn7de5zgntGLEIhFSwHcBvza9Y66eImV82M1SeAnArgG6mq2QljInQIlUtccsAdCWiIuWYXyUA\nADAtnD/DmCi/DwA+3sn9PvsA1AI4Wvn9dDYD0U1hFYDRyv5oAHuYeX+isURUDGAIjLjBQRi/I/e9\nVjVRLiFDEEUgNJdcIipQfnJgTIo3EdGJZFBMRF8loo4AimFMjOUAQETXwvC3pxxm3gojS2aqmQp5\nEoALm3i7+2Fk1BQg8TvtAdCXiPJMOSIwfkcPEVEP85o+ZvZPU5gG4HoiGklEJQB+CeB5zdjXABxD\nRJeast8DYDkzr1Xu9Usi6mIGkG9Q72UGuQvM3Tzzv7kuViNkCKIIhOYyG8bXrfUz1cyquQHAowAO\nwgiqXgMAzLwawIMw/Ox7AIwCMK8V5b0SwEkA9gO4D0bqZH0T7jMLxrvd4OOdPoDxVb2biPaZx34G\n4/fyGRFVAngPwAivB5nB4sO6YDEzvwUjKD4HwDYAWwH8Srl+FRFdaY4tB3ApjCD8QRiBdTU28SsY\nweOtAOYCeMC8v8U6GP+d+wB429weACGjIVmYRshmiGg6gLXM/KuEgwWhnSIWgZBVENEJRDSEiAJm\nodTFULJ/BCEbEUUgZBtHAPgQRobMXwDczMxfENGVFG0hof5IoFRo94hrSBAEIcsRi0AQBCHLyYiC\nsu7du/PAgQPbWgxBEISMYvHixfuYuTTRuIxQBAMHDsSiRYvaWgxBEISMgoi2+hknriFBEIQsRxSB\nIAhCliOKQBAEIcsRRSAIgpDliCIQBEHIckQRCIIgZDmiCARBELKcdq0IahpCmDZ/C+Z+WY49lXVx\nx77+xU5U14daRzBBEIQ0IiMKyprKXa+uwIylu+z9FVPPQceC3JhxS7YdxG3Tl+LSsX3x4LdGx5wX\nBEFoz7Rri+DOc0ZgSGmxvV/bEMas5WWYs26vY1xNfRgAUFZRC0EQhGyjXSuCfl2L8P4dk/Dbbxir\nBjKAW15agmuf+9wxThbaEwQhm2nXisAiYM70iTpuS0duQRCykaxQBNYHf0Qz01vnGaIJBEHIPrJD\nEZgz/Tcfn28fUxfkCUXYPNaqYgmCIKQF7TpryILMb/6dh6LB4BlLd2FNWSWumjAAy7YfAgCxBwRB\nyEqyQhHAIxh82/SlAIDFWw9i0daDxkFTEzSGIwhHGAW5wVYSUBAEoe3ICtdQQEkLOvKIjo5zy3dW\n2NtWjOBbT8zHkXe/1TrCCYIgtDFZoQhUg+DmSUMc5xpCEXvbihF8sc1wFf1tzgYMnDLLMUYQBKG9\nkR2KwGedQEM4gpWKhfDA2+sAAPsO16dCLEEQhLQg6xSB6iaaeuFIx7jlOyrwtb9+EnP9bo8+RQer\nG/D5lgMtJ6QgCEIbkR2KQHEOqUqhd0mhr+v3eiiCyc8txDcfn49QWNxGgiBkNtmhCJTJ36kU/PmM\ndldEFYFVf2C5kKrqpGOpIAiZTZYoAm+LIOAzdlBpTvZTZ67CoLtm47+LdyAvx/jVVdQ2el7TEIqg\nrjHcNIEFQRBakexQBMq2Ovn7DSJXN4RQ1xjG859uAQC8uXI3coPxFcF5j3wkKaiCIGQE2aEIHBO+\nYh14VZp5UNsQxoLN0cBwacc85JmKoLLOWxFsKq9OWk5BEIS2IGWKgIj6EdEcIlpNRKuI6Efm8a5E\n9C4RrTf/7ZIqGWxZNMFiVQ+MG6AXo7o+jMnPLrT3uxXnJ3QNCYIgZAqptAhCAO5g5pEAJgC4hYhG\nApgC4H1mHgbgfXM/pTjcQY7j0b0fnTVMe+2qXRWOY9065MV1DbF0rxMEIYNImSJg5jJmXmJuVwFY\nA6APgIsBvGAOewHA11Mlg4WujkBVCkFNwCDCwNrdVY5jucGA3Y6ivjE2fbRK1j4WBCGDaJUYAREN\nBHAcgAUAejJzmXlqN4CemmtuJKJFRLSovLy8uRIo94Vm2/8yZQygtsFQADUNIdQ0OCd+a+nLZGBm\n/OyV5Vi+41DS1wqCIDSHlCsCIuoA4L8AbmPmSvUcGz4UTz8KMz/JzOOYeVxpaWkzZdBsKwoiqPiP\nRvft7HmfW88YagmHejM19E/vfInj730PAHD79KW45rmF2gVwvGg0C9L2Vzdg+qLtuMa1jKYgCEKq\nSakiIKJcGErgRWZ+1Ty8h4h6med7Adiru77F5HDKZG+rsYOg8puYetHRnvfpUGB07b57xiqH+6e2\nMYxIhPHaFzvx4bpyX+savPbFDry0YBuG/eJNzFi60254J8snC4LQ2qRsPQIyZtxnAKxh5j8rp2YC\nmAzgfvPfGamSwUIXF4DGNRTQuIk65Ot/XYN/PtvejkSiqoCZPd1Ot09fZm8v31GBkwZ3i5FDEASh\nNUilRXAKgO8C+AoRLTV/LoChAM4movUAzjL3U4ouFqC6hgIaRfD4VWPt7Y4FyevNxnBUKWzdX40D\n1Q0xY3qXFCJsmgSp1AORCOPlhdtsd5QgCAKQ2qyhT5iZmPlYZh5j/sxm5v3MfCYzD2Pms5g55S08\nnXGBKKpryLGt/FY6F+bZ234VgRojOPuhuXjqo00AgNMf+BBfefDD2PERRiisdyid/sAcPDF3Y8Ln\n1ofCjr5Ibv67ZAfuenWFr3sJgpA9ZEdlsebLX2cdqIFjdTsv6G/pSjVWvHV/DX47e429f6gmtu4g\nzGx/pXsZBFv31+D3b65N+Nzb/rUUE37/vsM1pWLVPByoliI4QRCiZIUicMYCEm+rykINIuua1F17\nykDH/t0zVsYVx11wFo4wQpHmu4beXLnbuH/TbyEIQhaSFYpAFyx2ZhNpxquxA40mGNOvxLH/8fp9\nceVpcPnowxHVIjCesWTbQVTUNmq/7uOhq2y2M5MkHi0IgkJWKAI/mUJa15AmiPz01ePs7cLcxC6j\nF8zOpQBQ1xirCKwYAREwZ91eXPL3T/HMx5vQGEk+sJtIdYgeEARBJTsUgfZrXzcmuu2MF0SPlxTl\neo7R8auZq+ztetc6BRFmhCLRGIHVuXRvVX3cILIOaXUkCEIyZIciQGLXkC59VKdEVDeRru5AR61L\nERiuIcsiIIRNpRAIUJNSPVmiBIIgJEF2KAKdO0g34WuyhnTKQhc70BHjGuKoa2jnoVr8b1mZfa6x\nBS0CURCCIHiRhYoguq1vTx3dDpJOKXhf6wf3EpbhMDtiASvM9ZCZkZLiLwkWC4Kgkh2KALoJPHFN\ngX6946a7hmIUATOu9Ww2x56KoLYhjP2H67X311oEYhAIguBBdigC3VKVSQeLvSd89dp7L/ZuWKeO\nrXa1rdaliIbC7OkauvSxT3H8fe9pn5HIBST9jARBUMkORaBua+ZAXYqpwzXkI+OotGNBXFnygoGY\nVc3Cmk/1UMTbIlhdVukxOop8+QuCkAzZoQh0QV5dppDqSlIriwMa95HGynj66nEoyHX+ivNyAqhw\ntZnQhQFCCXoQ6RA9IAhCMmSFItAFdpNtN+HMFPK+v3uM++vcsAicrqGwpmgsFI7EVCH7QVtZnPSd\nBEHIBrJCEfiZ8HWN6XRVxrqAsi4YbbG/ugGvfrHDcUw31zeGvV1DFj97ZTme/Ci2k6hUFguCkAwp\nW5gmvdC4fXQ+f+VKP5XIum2Qd0xi6/4ax75uactwJBLXNTR90XYAwI2nDXEclxiBIAjJkN0WgY8x\nznUKvL/8HVZAE9JKw5qsoe0Ha9EQDnuei4ukjwqCkATZoQjUbe2XvLerR1dEpmtW4e506mfynbls\nl+fxDXsP45H31ie+AYCqumgAeuO+w7jgkY9jgtIe4gqCIGSHItBlBDkncOWoxgrQZQfpK5SbP+Mu\n21Fhb+vqDRZs2o9RU9+x9y/5+6dYXVaJD9btcYyTFhOCIHiRFYrAX4sJ55e8hbZ2wHH/xHGHluDP\n736JvZWxS1HO27jfc7xOEXkFsQVByF6yIljsa6lKTQqo6hrSp5XCcwxpgsVN5dE5G/DonA0xx6vr\nQx6jBUEQ/JHVFoG3k8hfiqnf41aM4M5zhqNzYXQNg5ZEF4doCdeUIAjtn6xQBCr6CT9xiqm+YR08\nx6vHe5cUolfn+O0nmoou/dStCCRrSBAEL7JCEfhZaMZfimly4933T9VErKsk1vZVimMo3PvGagyc\nMqsFpBIEIVPICkWg+/J3jPExXhsLcPQmSuw+aml0+kW3Xk48SZ75ZHNzxREEIcPIPkWgOa5tOqd1\nB6mTPzzH6xRHS6NzDTWn3bTOyhAEof2RHYpAu9CMD1ePOkb5bTkDzdqws+d9WhrdnN2cJ4oeEITs\nITsUgdaHrx5P3BpCb00k3lavHVJajJOHdIu5f26waVO3ps6sWeisDEEQ2h/ZoQiUbZ0LSPe1r6Jd\nv0AbgHYFi01v/nUTB6GkKDaVtCA3qHuFuOjcOO7JPBl3TyqUiyAI6Ul2KIKks4N099GNT1x97FZA\nXsHjQkURjB/UFf27FgEAvnpsL4zo2dE+961xfR3X6eZ3dwdra5wfL5VYBIKQPWSJIkh8XBc7cIyH\n9yyvm/DdDeiix+FpdqgWQZeiXAw3J3+CsbKZRe+SQsd1+qUuvdcy8JPBJHpAELKH7FAEyrauiZwu\n1dJxH58uIN22NbkGyHsqVi2CnEAAwUB0vBU/CAYoJobREPKe8CPM2H6gBuc/8jHKq+qTajknFoEg\nZA/ZoQg0X+bJ5vknG3Q24gKxMoC8c/8L8qKKIBiIuo+IohaBcdyJThGEI8DD763HmrJKzFq+K6nJ\nXRSBIGQP2aEI1O0k4wIqWitAs9i9rqOpep/bzhqGEwZ2AQBMHBrNJAoGyL6XYREYO7kBipFVt5zl\n9gM1+O8SY1nMDgW5dhtrP+2oJVgsCNlDVigCfbFYcuma2moBbZWxOobs6TdAsE2C3GDA/trv1bnQ\nDgQTRe9FMBa9B0yLwCX3+2v3esq7R2lZ3akgx57c/UzyUlAmCNlDVigC7RoEGp+/Dn/po8r9FbXg\nVhzWV7n7ntYVAVK+/BXXUE4w4LtKWW2hnZsTsN09ftw+ogcEIXvICkXgII4/P+GlGpMgfu2AOSbg\nHB8NHEOZ/KPPIOVeqmsoJ+CdeupFXWPUZRSJcNQS8DHJS4xAELKHlCkCInqWiPYS0Url2FQi2klE\nS82fC1L1fKcsyraPFFD9ffxlB1m4rQPL3UIOReCyCCi6HVCUQo65k+MRI9BRH4oufB+KsP382sYw\ntu2vcYx9ZfEOPPnRRntfYgSCkD2kcoWy5wE8CmCa6/hDzPynFD43Bv1KZOp20+MFOpeRTtMYIQLT\nNRTTrTSaKWSdCRAhTMb4YNB/H1PVIghH2P7KnzZ/K6bN3woAePyq43HeMUfgzv8sc1wrMQJByB5S\nZhEw80cADqTq/smgm/B1CsLfPeMUi3ls6xWH87htBVC0XoAoek1OIOBbaakWQTjCMZXGADB7RZnn\ntWIRCEL20BYxgluJaLnpOuqiG0RENxLRIiJaVF5e3qwH6tI4nQHcJC0C7Ye/t6JxT/6O4jLLHRSA\n4hqK3tdQBMZ2Uq4hjUWgfQ+FCDMiEcbVzy7EJ+v3+XugIAgZSWsrgscADAEwBkAZgAd1A5n5SWYe\nx8zjSktLm/VQP/78pO+pSUP1k6HkCCLHZBnFWgGqdRDUlEAX5QVxylBnR9M6TYzADxFmVNWH8NGX\n5bj5n4t9XycIQubRqoqAmfcwc5iZIwCeAjC+NZ7r/Hhveh2B4546t4+mhQWBPKuM3e4pNVispp5a\n43KCsXUE1vjLT+jvOFbXqLqGIp7uHt1vwKEzmqEwBUFIf1pVERBRL2X3GwBW6sa27IOVzRZ6Y23f\nIc0Yt+LQZg0p29Y51X1kxAi85XFbI85gsXdKqM4lFuHkLAhBEDKXlGUNEdHLACYB6E5EOwD8CsAk\nIhoDwzOyBcD3UvV8FT8TdbLoahB0biLdGHew2CuATRTV2DlKryFyxxoUmYIBcgSLl24/6OlW0v0O\nTn/gQzxy+RhjjPcQQRDaCSlTBMz8HY/Dz6TqefHQBYVbzDWkmdhj+hFZk3YAgFJZHC0cc7mGrBiB\nIqvaYiI3GLAbzqnXAkBjmLGnst7e//eiHZ6rosVLRn1jeVnMewiC0P7Iispi7UTdnHs67u99Qhss\nBnkuEkPkDBZHLYKom8iIERjHcwNOpZbofarqQrHvEeciq0md6AFBaN9khyJwbHsHapNFX0egCxYr\nMjiyhpxKSk0fjdYUOO9PinWg3jPR6wQ8XEOvLN7hCCqrWDEF0QOC0L5JZWVx2hAvaNsS94xbXGa7\ng8gx+VuB2KDmq97dgI49xlj9hwx5KOEbBTWnZy7d5XlcisoEITvIEkXgPQM2K1isrR3w1jQ6i8Bx\nrVJQBtUigNNSsLYdFgGa/j4vLtjqeTyi9EYSBKH9kiWKILqtazHRHPTrFJOjOlg3npTxzpRRNV6g\nHDevyHG7hhLIGdZ84S/bUeF5XLJHBSE7yA5FoG6n+uNWEyyGo/uodx2Ber07gyiqUKL9iNw+/0SK\nra7BOxagQ2IEgpAdZEewWOPDbyl0dQGk+IB06xq70z6jq5IpdQEUPa6Od1gErkTQr45Sa/cMdisr\nlvkhLFlDgpAVZIciULdTMKv5KRZzp7B6tZtgsGfWkNqVVHUNxcsaOm149xg5K2obk3grYMHmtGge\nKwhCiskKRaCbnFNxf6+ve2NbGR+IuokCLt++va20lSDlGYEAFPeR2zWkbrfki4pJIAjtmaxQBKmb\nIM17Ktu6rCE/dQeAu44gGix2WgfkGOu+p9d9m4O4hgShfZMViiDV6OoU3JXFXu6ggOu/gCOI7AgW\nq1lDUa47ZZB9T3fsoaUQPSAI7ZusUASp/qKN6SnkcVwlQNGMHN2Xu+oOIjirjKMuI8LI3p2cF9nP\nEItAEAR/ZIciaMVvWu1SldrAsRIsZqX1hKPLKHnGIVSXkbuOQCZvQRD8khWKIBUBYv2zvK0Do61E\nVB7nUpXxBVQnfPczdAVyLWoRgLCp/DDumbES4Qhj7pflWLz1YIvdXxCEtiUrFEFrtkjQ9jVyZRN5\ndR91V/KqLqBEbTLcFoEfRdC9Q17CMRZT/rsC0+ZvxbIdhzD52YW49LFPfV8rCEJ6kx2KoDWf5SeV\n1JXto8rn1dYhpujMzhrydhlZ13jxx8uOtbefnnyC9yAXRECHAqMIfV9VfYLRgiBkGtmhCNrIX+6e\n/FlZjIYRv5GP25pQA8d27ADqcYIuUH3/JaPs7R4d8+1tvy6zhlAEH6zdCwB4fO5GfxcJgpAxZIki\naBtNEHBM/qo8yiDVNQRoFUQ0KEzQFcip91Wrjo/oXKCMTz6OsL+6wd5esu2Qr2sEQcgcskIRtBWk\nmfHVwLExThlmxQ5cDi1d1pCjQ6ljvPe1OleSIAjZiyiCFGK0j4hO1I6sIXOMn9TWmCCyff9oDyJS\nT0A/+eua37UEkQjby1sKgpA5+FIERPQPP8cEJ7qup0SIfvn7nIsdMQJH6wldMRs024pSaOHPgLMf\nmovBP5+NB99ZZ/dSEgQh/fE7FRyt7hBREMDxLS9O+0MNEFuQEix2ZgyxMsZ5H10swJrMSWlSF/s8\n7/u0ZK0BAGwsrwYA/PWDDVhdVtmi9xYEIXXEVQREdBcRVQE4logqzZ8qAHsBzGgVCdsJ7kk6WkdA\nOH14KQBgcGmxNpdIXYRGzRrSdjjVuYYcayRHx192fF8/r+EbMQgEIXOIqwiY+ffM3BHAA8zcyfzp\nyMzdmPmuVpKxRRg/qCse+vboNnu+bsImAq6aMABL7j4bQ3t0jK5iFnO9ek00WuwVOAbiBYs97gPg\nlKHdPOU+pk8nz+OAERN4ccFW1DXGrnwmgWhByBz8LlX5BhEVM3M1EV0FYCyAR5h5awpla1H+/b2T\nHPtFecFWea6hADhmeUr1g5mI0LU4tspXVxegBoidsQN4jtceV55VkOP9+1i5U+/ieXPlbvzitZXY\nuLca91w4UjtOEIT0xq8ieAzAaCIaDeAOAE8DmAbg9FQJlkr+e/NJ6FNS1CrPsmMBLh+/7stfh/1V\nT7FuJvu+jvG6bW+XUW4w+chxrWkJbDtQnfS1giCkD37/7w+xMXNdDOBRZv4bgI6pEyu1HD+gq6PI\nqjVI1CvIwqsHEaBaAdEKYmf3UVewOBDfmjC2FUWQk7wiyDOvqawNxZwLSxqpIGQMfv/vryKiuwB8\nF8AsIgoAyE2dWJnNiYO6xhxzq4FE02S8gjJlTXvPojV3t1JdEFm9NFfTbyInTh+KDXsPAwAq62LX\nQm4MiyIQhEzBr2vo2wCuAHAdM+8mov4AHkidWK3L2P4lAIyePKVmL55PfnYGcpJItB/QrQhb99cA\nAJ6/djwO1TY4zuvy+t0qQjt9enzJk6ugjDQKQrumsqoINBbBtOvG44qnF3iee3NFGQBg7e6qmLqB\nUDiiexNBENIMX4rAnPxfBHACEX0NwEJmnpZa0VqHtfeeZ3/1Xj6+v328b5fkYgj/+8FEVNQYX8aF\neUEU5hU6zrtz9hOlVzraU7uOO77wPdJK3c/zs6378i/K1/+J7K6ss7dX7KxwnAuJa0gQMga/lcXf\nArAQwDcBfAvAAiK6LJWCtRYFuUHkNCFQ6qZTQS76ddUrD4KzYIztpSqTf5b65e9cwjLWUlDHA85m\ndH6CxfFcQ1V10dhAQ8hpAVz59AJ8umFfvNcQBCFN8DsD/gLACcw8mZmvBjAewN2pE6sdok3tTM5S\nMG4VjQXYk78SVVDTSq1xFrpsIp0iCGoUQedCZ4io1qOW4DdvrNa8gSAI6YTfGEGAmfcq+/uRRQ3r\n3vvx6fZi88mi1g44jid9o+immkHkx/+vW84SDkvB+7E6i6BX5wJU1EaDxDUNsYqgqb8zQRBaF7+T\n+VtE9DYRXUNE1wCYBWB26sRKL4b26IDhPZuXLWuUlUW5/AQjHtGvizOWoFuPwNGbyOOr3ogdqFlD\nycUIdOmtOougVFngBgC+94/FMWMkhVQQMoO4FgERDQXQk5l/QkSXAJhonpoP4MVUC9ceiLaAcE6o\nV5zYH1ec2N/jiuh4r7lZnfBB3i6geJaCro4gqFEEOpdRSVHi9Y5VPbBk20GM6VviCG4LgpAeJHIN\nPQzgLgBg5lcBvAoARDTKPHdhSqVLcz6d8hUcrGlIPBD+K4j94NW51K1o/FUWex9XyQnqYgSJvYqW\nRbByZwUu+funuOWMIfjJuUcmvE4QhNYlkWuoJzOvcB80jw2MdyERPUtEe4lopXKsKxG9S0TrzX+7\nNEnqNKF3SSGO7t057hg1RnDnOSMAAN08+gq5x/vB7e639wnagLSftQmWTz3H3vYbLPZi24EazNuw\nD/UhI37w2pKdAIC3Vpbh5YXbEl4vCELrkEgRlMQ5VxjnHAA8D+A817EpAN5n5mEA3jf3swMCLj2+\nL7bc/1UU5CZueBdTiawqCI2ysGMESL6yWJ3wOxVEJ3ldUV1JYWLXEGCkkU6bvxUAsKvCqDu46Z9L\ncNerMd8XgiC0EYkUwSIiusF9kIj+D0BsdFCBmT8CcMB1+GIAL5jbLwD4uk85M56WastMINv37p7U\ndZlCyW6rNMcisJixdJfvsYIgtD6JHL23AXiNiK5EdOIfByAPwDea8LyezFxmbu8G0FM3kIhuBHAj\nAPTvrw+qpjtq8Zcf7K6kamWxywJQO5qq59S1CfysWewrRqBRBJ2SUATJ8v6aPejZqQDH9InvdhME\noWWIqwiYeQ+Ak4noDADHmIdpQhvoAAAgAElEQVRnMfMHzX0wMzMRaT3izPwkgCcBYNy4cWmThzjr\nhxM9u23q0NURtAQEciiFqGuIXLEAdTuxglDRBYs7xGk90Vyuf2ERAGDL/V9N2TMEQYjit9fQHABz\nWuB5e4ioFzOXEVEvGEteZhSJgsM6mqsHLE3otgJ0z3C2oVaOa+TQuYB0MQJVQTx+1fG46Z9xPYU2\nsqi9IKQfrV0dPBPAZHN7MrJo3WN3W+nE452o6xR4KQVHiwnytxiNn4IyneLIVRTB0B4d7O1RCdw5\nt09fGve8IAitT8oUARG9DKPwbAQR7SCi6wHcD+BsIloP4CxzPyvwaxH4+V72+qpuWrA4Ol5nEagK\nYqqyHKVqKaiXTj55YFzZX08ycPzZpv0Y9au3He0sBEFoWVKmCJj5O8zci5lzmbkvMz/DzPuZ+Uxm\nHsbMZzGzO6uo3eJbEdhf/okvICKX4jCuCVCcGIHyX9xPZbHK1ScNtLdV15CfdtZN5aF3v0RVfQir\ndlUkHiwIQpPImsZxbU2yrqF4eFkN5NqOLl4TrwEdPLd1OBayCaoWgVqY5v89Iwl6EQ3/5ZspDbYL\ngmAgiqCVaH6wmNUd454AeptrL58/qpdP15Aqk2IR+JjA/ax65seysGiMxF/FrCEUsd9bFIEgpI7U\n5QAKTUJNB/XGmTLao1MBVv76XBTnBbF5X7U1xLGEpZ/CsWQnWl18IRnPUGOYkSgLNaIEyQVBSA1i\nEaSYf904AZef0C9p37mf0daYDvk5ZrfSaIsJR38h9RrNjZN17WstDteN1IwiN42hCD7btB/f+Ps8\nbD9Q4znGLrBLTjxPdlfUYdTUt/HlnqoWuJsgtB9EEaSYcQO74v5Lj/UV/AVclcKa49o6AmXbT/qo\n49qkLQJN9pHrPpYC7Nc1tjXVjoO1uPzJz/DFtkP487tfej4n4gqehyOMEb98Ey8u2Ir6UBgrd/oP\nIr+zejeq6kKYNn+L72sEIRsQRZAheNYOuCZdde0Dhw9fkynUHHTVyu5Yg/W8Mf26YJjLOthdWWdv\n769uQF1jGFNnrnKMia5yZvzbEIqgPhTBr/+3GlNnrsbX/vqJ1ppwE7CVia/hgpA1iCLIMNzZQc5z\n0UyhgMY11FLZnQFNXMDtGrLKDboW5cYooer6aKuOA9X1eG7eFjz/6RbHmMawoQCsyTusuIq+2HYQ\nAFBV56/lh6WkEmUrCUK2IYogzbCnqDhf7rppzNliQtn2UUGcLH4WuwEAKzGoS3FezCupi/ocrG7E\noi2xZSUhUwOEzBuFlM95O7XU51+x5bYKiSIQBAeSNZSmuKfrU4Z0AwBcNLo3ivKM/2yj+nq3c3DW\nEVBKUi91cQd3jMBalKY4LyfGbXSgOqoIAgGgtjEc8xxr0rZWO7MsBKKo28hvjYZlrUSk35EgOBBF\nkGZ4zVEMxuDSDo5unG/8YCKO6tXJMU6NEVhTY35OICWpl9pqZddkb71OMBCrkPYriiA3GPD8Urcs\nAUsRhJTaA2tCZ1+NOQCrBk4UgSA4EddQmpJo8j6mT+eYL2zV7ZMTDOAn547Aa98/JSWKIKizCBSZ\nXrnpJFsTGIrAeY8DhxVFEAh49lAKh50WQSgcHWMNV4/FIxosFkUgCCpiEaQZd5wzHLUNIXzjuD54\n/MONSV1Lrn9vOWMoAKAxBWkyOneQrnI5EKCY+MRbq3bb2+s0uf2NtiXg/BeIftn79flbMotFIAhO\nxCJIM7p3yMfDlx9nxwGSQV2hTCXVMQJ9awvFNdREGayv94htERhKTV2yM+RT0dmKw4cF0RiOYO6X\n5cmKKwgZiSiCNKan2UeoZ6cCX+N1QdNUdGfQdjENOF1G1uSbE3B3SvWHZc0s3XEIb6/a7WhHbd27\n0adryFIAfiyCv7y/HpOfXYhPN+5LVmRByDjENZTGfOeE/uhWnI9zRmqXdnYQnY+9C81aEv06yE5F\nEE3xbJoQliJ4Yu4mx3G1sM6vzz/sykCKx5b9RpFaeVW9X1EFIWMRiyCNCQQI5x1zhO9JVDeqpWoH\nVPy0sHB0JQ1A3xsjDvEmbdsiSNDF1MJORfUhhiW6WwEJQntEFEE7Qm1DkWr0E77zuNpGuimuoXiB\n4GR8/gAQtlNREysO6zVWl1U66h0EoT0iiqAd4kcPdCnKbd4ztL2GosdV15CqIL55fF97++3bTsPE\nod21z4lnRLiDxXWNYWzbr+875C5Oi4esfyBkE6II2hF+PS+zf3gq3rn99GY9y8+6BqoiyAlEt4/u\nHS2E611SgK7FeUk/nxBtUW1N8D94+Quc9sAcbRZRNAPJx/01vZoEoT0iiqAdkXhRG4ORvTuhtGO+\nvV+cF0z6WTpFoFukxpFZpJgNxloKST8egGIRmDP7u6v3AAD+9fl21MVrV6HRmBv2RmsZVJmk7kBo\n70jWUDvEK4301xcdjRMGdo05/vFPz0BxomXCPNDFr90N7qyv9mAgurJa0DWmqejSR3/5+kqsLqvE\n774xynHcsgi8KpjfWlmGm/65BI9dORbnj+rleD+d4hCE9oJYBO2IePPV5JMHYmTvTjHH+3Utcrhm\nvBaQ8UI3gQdigsWxx4OuvzovuU8dpo8bWEQ82k5YfLHtUMwxKxXV69e0alclgGiFs6rQfCYlCULG\nIhZBO6K5WUNr7z2v2UFSdw8irxiB7hk/v+BIPPnRZuw7XI88t7ZwQUTKWgWxM7XXYjXx6gisY9aK\naqqiE9eQ0N4RRdAOaepUXpCbfKzAjXMdBDjcQe4Movwc52QfILKthZxg4rew2lZ7VRYfro9drCYU\n8XYlAdF4Q8BWBNFz0qROaO+IImhHWBPrkDgLxqcaP5XFwQBh4S/ORH7QqXhyAmRbFDkJLAKVkE/f\nTXRNg9jx1le/9fyABIuFLEIUQTuie4d8vHDdeIzpV9JmMjgDwc71COx4ARF6dIztnxQMEIKmJZDI\nNVTTEP3ibwwzdlfUxRltYMUSvNJLrXOWtaIqtFRaBBU1jTjcEEKfEn+xGUFIBaII2hmnDy9t0+c7\ng8XOuICVreOOEUSVRSBqESRoq6HOzeEI47bpXySUzbIcvF1DTtkCrRQjOPWPH6CyLuRYdEgQWhvJ\nGhJalNg6AmcQ1hijuzaqSJJyDYUjWG1m/eiYOnMVps3fCiCBa8hDAaVgOQebyrrYWIYgtDZiEQie\nnHt0zyatieAuIvNqMRFjEdiTcNQiyPURLLbYvL8m4YT6/Kdb7G13/6Ln5m3G2jIzbbSVXUOCkA6I\nIhA8eeK745p0nbsZnRoX8FIKKsFA9FxOQG8RDOxWZLeJBoC56/Z6jtuwtwpDe3TEK4t3OI43hqKf\n+MyMX/9vtb1/9+srcdnYvhIsFrIKcQ0JLYr7y589XC66ttpG+misRTBhsLMiWrVUSjvma62Bs/78\nEQDgzv8scxxX21Z7dTf9YttBh4yiCIT2jigCISEf//QMfHjnJF9jYwrKrOMB7zGAWggXVQTqRJzr\nihcU5Eb3jzGrpXVZRgOnzIo5pgaLvaqSQxF21GIkcg3NWLoTQ38+27O/kSBkAqIIhIT061qEgd2L\nY46/c/tpeOG68Y5jjqwhQHEHBaLFZRqLgOBddewuPLMm5gABQ82aiZ6d8/HgN0f7ep9whG1LxWtR\nm3CEk6os/sObaxGKMPYdltXMhMxEFIHQZIb37Bg3XdXhGqI4LSaUedZSEurc644XWBXQxXk5ju3C\nJLqoNto1Bd7tJhxN5xJkDVlKQzxIwH8Wbcectd4xGyF9EUUgpAwKqE3nnMVlnuMp6jZiRTu448Zn\nHtUDAFCUH7SVRIAoqT5JVgqpZ3FZJJJU1pD1PpJdBPzkleW49vnP21oMIUlEEQgpw7EGgWadAsB7\n0i9U+h6pbppJI0rteEBhbtDuSUSkVzBePPPJZuw8VIurn10Ycy4U4aTWI7Ae61Wf0J5Zt7sK75lr\nQAiZTZsoAiLaQkQriGgpES1qCxmE1BMg2GZAUK0sjjNhW1/4R/fubPv/uxZF22QTgLwcQ0kEA2Rn\nFzHr10jw4s/vfomfv7oCa3dXxZxzf9kn+tK3FF59qPUVwT8+24pT//hBqz8XAM59+CP83zT9/77X\nP/85fvBy4opvoe1pS4vgDGYew8xNS1gX0p4AkaNi13YNxXHhRAu6gK+P6Q0A6FSYg5+cO8K+Z54Z\nPDYUQSDmWjclmvWZ535Z7nk8HGGHFZBoYRrruc1RBF6L5fjh7tdXYvuB2iY/N5W8v3Yv/rdsV1uL\nIfhAXENCSvGKC8Rz4agFxercaE3mRFAUQcDRikJVMGoG0e9dK5UlYun2Q3hr5W57f1N5Ncb/9j08\n/fEmz/HW6zQ0QxHorI5L/j4P339xcZPvKwh+aCtFwADeIaLFRHSj1wAiupGIFhHRovJy7y83IX0Y\n0K0o5pijJXUgWmasC+oSSBt4jU7yZMcIggEgN+AdI8jNicYRunXIRzJMm78VG8ur7f0New9jb1U9\nnv1ks+f4qGuo6XUEOqtjybZDmL1it+c5lYgEqoVm0FaKYCIzjwVwPoBbiOg09wBmfpKZxzHzuNLS\ntu2oKSRm5q0TY4rOAqTUETiKy9y9hqLbXoqAEM0IMiwCMsc6LQJVv1gKgsGO510/cZCn/N075Hke\nB4CK2gYAwK6KOuw8VItFWw5g7L3voqKm0Xyucf9UWAS+r5fcVaEZtIkiYOad5r97AbwGYHz8K4R0\np3NhbkzRmVFZHG3vHG034X0P9as+zOxYW9heOQxAnrmgTY4rWKy6hiwFwezsfHriIGe7CovfX3Ks\n9t3UL/KLH/0ED7+3HgeqG7BsxyHz3YxzDQmyhi569BPc+8Zqz3PNVgRiEQjNoNUVAREVE1FHaxvA\nOQBWtrYcQtM48oiOvscSAScMNCbe+N1HEXMuHGFcONoIFn/9uD72ZKsqiyA5g8UO15ASbHAe9/6T\nz8vx97/CvsMN+GTDPlsW9f71jfEVwfIdFXjGdC99unEfVu6ssM/5XGRNy9f++knzbiBkNW3RfbQn\ngNdMczoHwEvM/FYbyCE0gVk/PNV3hgsR4fGrjseW/dWOiZbiZA1Zk2qEGYO6F9sLtqzaZUyaBGcm\nUo4SI9D1J1LXP1aPv3v7aTj7IaMxnbuNhR+2HahxvE8ii0DliqcWOPb9LrepY8Pew826PpX8Z9F2\nzFm3F7+5+Bh0TzJeI7QOrW4RMPMmZh5t/hzNzL9tbRmEphMMUFKLxhTn5+Do3p0BODpJOLjx9MEo\nzA3ixEFdbfeOu/UDKTECq2NoTPqo6hqyYwRO15CqFIb1jFo3fi0ClV+8thK1DWHbWqlvRtO59uzj\n/8kryzF7xW5MnbmqrUURNEj6qNDquO2Bsf27YM2956Fbh3z7q949L6quISsQXFKU65jYvWIEYCOo\nbKF1DSWh3FS27K+2nxvPIvBqZaESiQBvrijD3ipj7eW9VXVYsGl/k2RqbfxaiBLHSF9kYRqh1fAz\nX1iTqvsL2dolECYM7oafnXckrhjfH6vLoktUqj2JrImdwQ6LQLfyWU4SK6KpbCqvti2R381ei/GD\numFMvxIAwPtr9qAgN4hThnZHbQJroaYhhJtfXILBpcX44I5JuOiv87C7sq5JMrU24Qj7+v0l0QpK\naGXEIhBanOtO8U7RtPKA4k0IwaB3HYG9Z8YCbp40BJ2Lcu1UUsDlGtIEi3Urn6nH43VUdVNW4azq\nVbOCrn9hEa582ogFJFIE1vlNZv1CKpXA4foQlm4/1GL38+vWohhbUEgXRBEILc49F460g7wq6le9\njnNG9gQAHNe/xHWtqURc49UJ3CtryJ0+qioOFdVSuPfiY7TyuWkIRxxrGlTXhxCOMH7x2grHuLqG\n+K6h1uxTdPv0pfj63+bZdRDNxXecW/RA2iKKQGg1is0lJuNZBJNG9MCm311gB5jduDOOHNXL5P3l\nH88isLqc5miyjBLRGGKs3xPN2KmqC2H93iq8uGCbY1wii6Apq5sdqmlw7Ku++g/W7sEp93/gWe28\nzmy0t7+6ZRbSsSwCqW7OXEQRCK3G05PH4SfnjkDfLoVxx3k1j4suauN9jbvFhDWZG1lDSrDYlR1U\nnB+MuW8yiuCh977E4fromsnqtsqrS3bEvU+iGgQv7vi3cy3mQXfNxg/Nbp/3zFiFnYdqsacidrLv\nVGgoZN1az8liufESuYjEIEhfRBEIrUa/rkW45YyhcesIdNjxhThj1MncDhYz23EHIJpxZHHykO4A\nXMpCE0ewmHHLKdpzFbWNMd1AmRlPfOTdsM5CtRj8Ztd4xRFmmt0+bTecxy+sY77RwO9gdUPsySZg\nWQKJ5G7Kf3ehdRBFIGQE0YnNVZVsKghjPQKP9FG46wicf/J/vOxYzLjlFJR2jBY6BRNYBAO7Fcct\nQJv7pXOpRrf/3yvd8vbpS+1tt8tHR7x51yq6e27elphzlkVwoIUUge0aakWLYHdFXZNbdwuxiCIQ\nMoKIHWh2UmSuU9y7pFDrGtK1ngCM9Y9H93MGphNZBEX5Qay773zt+RU7Kx37Vzz1mb09oFsRznv4\n45hrVGXht0pYNxHuOFiDsgrDWnh2XmzH1E4FhkVgKYKN5Yfx+hc7fT3TC/8WQZMf4WDLvmpM+P37\neHxufCtL8I8oAiEjYPbWBEN7dMQjl4/Bn7452p7wA+SczNVCM11BmUqiGIH7Hn/5znH2NhGwpsyp\nCJZsM1I183MC2Lq/Buv2xK6KpvLtJz+LOeZlJeg+iCf+YU7c+1tV1DUNhjvq3Ic+wm2KRZIs0WBx\n/HEtZRFsP2i09vh4vbSnbylEEQgZgTXneaWeXjymDzoX5tpfnDnBgHMJSx9N51RUV5K1MhoArJh6\nDt778ekx4/t3ja7F0LNjgbYd9fEDuiR8to4xv3kX1z3/uePLPZErxh7n+lK3dhvChiKwWnY01dVi\ntQNJGCxu4RiBn9u9uaIM0+ZvadHntkdEEQiZQZzgp4X15Z8bMBa46VNSiD9e5mwv7WeBe3XCuuWM\nofZ2x4Jcex1lFbU9Rddi/boGvUviZ0sl4oO1ex1f7n4VwbefnO/Yt9pduDOVkmmap2LJobqGUum/\n91OPYnHzi0twzwzpcZQIaTEhZAR+soasCTwnGAARYd6UrzjOn5ZExXAyqEVqVjqqmwcuO9ZuX91c\n5n5Zjpr6kK+WHQDw+ZaDOFDdYCspa8J2T/wNoQjyc7zlj4d1P8c6zx7xgpayB2zrUJKQWgxRBEJG\nEC8d0sL60vVy/yy5+2ztJN1crIVyAP0ynCVFeWhs4he3m8nPLgQADPRYHlTH8fe9i82/N6q9Gy1F\n4HJh1Yci8L/aRBQvi8DTTdRCE7dkC7U8ogiEjKA43/hT7RLH9dKtQz5OHdYd3580NOZcPJdNc8nV\n9DtSKcgNoCEUO4GddVRPvLdmj73fp6QQOw/VxozzojHsf0JU507bNRSKtQj8cPv0pehSFP19WvpN\nVQTuNuJAy/UailoEbWcS1DWGkZNkS/Z0pn28hdDu+eqoXvjNxUfj9rOGa8cEA4R/XH8iThrSLeH9\nkmkslwg1RqB+Cf/35pPt7YLcoKdF4P66tdJhTxqc+B38Kgw3lgLxsgiYGY/P3YgdZmaOF699sdOR\nlurlGqryqFpuqXnbUjJt6Rk68u63cN0Li9pQgpZFFIGQEQQChKtPGoiC3Oa7d9bddx6eveaEFpDK\nQG1bYX1tv3LTSY4soYKcoOcX99kje+Ler0eb3FnvF8+NNaJnUxw4Bmt3V9qrvbn7EDWEIiirqMP9\nb67FDdMW+76nl2vo2uc/jxnXUhO3pVDbOkbw0ZftJ31VFIGQdeTnBH1lD/klLxjAY1eOxXfG98Ml\nY/sCAAZ0K3Y+MzfgaREU5gXx3QkD7OZ3VsVyUZ7Tazuk1LjfZcf3xQ2nDW6yrDdOW2wXm9WHIo5m\nd/WhsD2ZV9YanUnrGsPYdzh+czovi8BdS2Gcb7LYDmxF4Dr+5Z4q/PmddZ4xBIkrxEdiBIJgclSv\nTujfNfkUz7xgAOeP6oXzR/UCM+PyE/rZvmMiwz9fkOPtGrImfksx6SyC3iWF2FheDWagOK9pVlFj\nOGKvswwYFsA9M1ba+/WhCA6ahWvWxHn1swuxcPMBu624VzfTsG0RxH9+uJnrMlvoYhlXPb0Ae6vq\ncd3EQSgpcsaEQhHWLkokiCIQBJs3f3Rqk65TC9aIyFGZnBMgNIbZCBabvu1Th3XHx+uNVFIrXdO6\nhVX1W5jr/F9TTessyk/8v+3g7sXYtK/acezRDzY49utCEfx7UbQr6qzlZXj+0y2OMQs3HwBguLxy\nggFU1sb6/v22mAi1kElgpb26A/NWpfShmkasKatyxIoaQhFfxYR+aI/WhbiGBCGFWJNVvhIsVttw\nWxbBBDM4bO3nuZradSqITv5+vmz/9b0JGNXHuabDI++vd+wvc61StmTbQcf+8h3R8xWmq6iyLnYx\nm2c+2YxwhBMWuLXUmsWNIe8YgbX7lw/W4ztPfYZ3V0ezsfxmRPmhpRRaOiGKQBAScNrwUhzTp1OT\nrj3vmCMAGOmj5x5trL52xzkjcONpgzFpRCnGmgHlRy4/DrN/eCo6mhO++vF6XP8STFC+bq0J9eQ4\n2VGdCnIx9aKRTZIZMGoNLnp0nr3/zuo9+HzLAZz54NyYsW+u3I2l2w81yyLYtr8Gj3240dfXtjZt\n1tQEy3cYwfAbpkWzeppaNe39/NZbTa61ENeQICRg2nXjm3ztA5eNxs/OOxL5OUHccfYI3HDqYJQU\n5eHnFxzlGFeYF8TI3p1sC0INFt90+hA7HZMIGFJqtLm47Pi+6Nul0OHescjPCSQdnN1/ONrYrrzK\nGSC+69UV7uEOqutD6KBYLfk5gZg6hXiK4g9vr8Ws5WUY3bczTh7aPe6zopO60ySw9mobYuMYLWkR\nNHrUg2Q6YhEIggf9uxYlTNO87Pi+9he8jrycgN1jKBCgmCCmGyve0KkgB4PNTKFwhNG50Ggd3aNj\nPnqXFGLT7y7AJWP74vqJ0QyiW84YYm8Tke8WFBaJsoPicbg+ZMcKggFCoSug3a04L65FUNrBWA9i\n4ZYDWL2rEjf/czFmryjDvxZuixmrm9StArOahtg4Rrw1ofdW1XkGwXU0tlDQO50QRSAIHnz00zPw\n9u2nxR3zp2+Oxoqp57boc63GeREGThzUFYCxbsBZR/XAg98cjR+dNQxA7HKew3t2wNfH9HEcsxag\nOXVY/C9si3iTZSKq6hrtL/6ivCBq6p0Ta15OIG7WkHXt4boQXl+6E2+u3I3vv7gEUzwsEcs1o7uf\nl6LQKQ9mxvjfvo9bX/pCK5vu+e0JUQSCkEZ062BYDEV5QfsrubKuEUSES4/vG9MUjhH9yu5lWh4X\njDLiEkce0QkvXDcej14xNuFzv3Jkj2bJ/eKCbXjg7XUAgOK8nBiffFlFHeZt2I9dh2rRGHbWLwDR\ntZ4P14fsmgqLv83ZgD+8tRZf/YuxoI81Ec9ZV+4IcFtf9bWNsV/3usm72nQjqYHlRLRH15DECAQh\njbh50hB0Lc7DJWP7orYxjL1V9bhqwgBf13bIz8G7t5+G/kozOncrjakXjsTU/62Oufa7Ewbgg7XG\nEpuj+3bGMjPg6pflyvi+XQo911MGgBcXbMWSrYewbMchfHDHJKzaVYEv9xy2C9jeXLkbF43u7bjG\nUjAA8OA767DrUPTel/z9U2y5/6sIRxh1ZlttLw+UWzEt3noAw3t2xKGa2CwoL/ZU1uGVxTtw0+lD\nEgaemRkRBv4xfwsuH99fWw1fXlWPlbsqcMaI5inhlkAUgSCkEfk5QVx90kAAxsR+/6XHxh3v7s0/\nTBPXeGbyOAzv2RH9uhahKD8Hw3p0wKDuxRjzm3cBON1HM26diIFTZjX5HYaUdsCirc5U1J+cOwIP\nvL0Oa8uqMH/TfgDAhN+/H3NtRW0j/vHZVu29/+qqhbCY/vn2uDLtV+IfdY1hXPrYfIwb0AX3XOgv\ns+rh977Eywu3Y2iPDo6FiLwYdNdswz3WEMZTH2/GY1eNxbF9S2LGTX52IVaXVWLdfed5tv/esq8a\nv5u9Bj/4yjCM6ts55nxLIq4hQchg/LTnBoAzj+qJfuYE9q1x/XBc/y4oKcrDlPOPxGNXjkVOMICX\nbjgRM289RXuPV79/cswxq+JYpXNRbsyxq04cgLOO6oGlrtoFP+QlKAS7743V+Plr8bOaVu2qRH0o\njOr6kF0TsWjrQRw0LYIcV8xly75qhMJGE77n5m22s7kWbz3o2VnVwuo1ZRW37TxUi4senYdRv3ob\ni7cecIy1lizdcbDWsz5jd2Ud3lm9B1Ue51oasQgEIYu56fRoptHJQ2KDypNGlOLDdUZztVF9OmPN\nb85DYySCY6e+g6N7G7UVL/3fiejRKR9vLC/D4boQOnhUPgeDhN4lhXhvzV5fcnXMz8FNk4agsrYR\nT3wUu0j96cNLMdds+vb0J5tjzrtZtasS337iMyzdfghPfPd4+/jBaiNl1qo63ne4Hq9/sRP3zVqD\n7h3y8PtLjsWvFVdaeVW9wzXEzHjk/fU48ohOOO+YI2wl46aqPoS/frABz18bTUUOEBAG7NqMlb8+\n1/G7s9xlHQtiFWtLIxaBIGQww3p2wBkjSvHAZaNTcn914soNBlCYF0Snglx8/NMz8K8bJwAATh7a\nHUN7dMRtZw3HL782EgPMGEWAYBfi5QQI/bpEXSr5OfGnnqr6EG45YyhOGNjV83ynwuQmx43lh21r\n5Hv/iHZWtWIZtY1hzNuwD1c9vQD3zVoDANh3uMFRlAYYsQI18LxsRwUefm89fvDyEgCwLQwvPlxX\njmnzt2BT+WEAseszXPzoJ459q3YkUYpySyAWgSBkMLnBAJ67tukFbzo6FuTEuEtU+sXxk/cxs5eO\n6dMZ064bj6XbD6EgN4hLxvbBoq0HcNrwUlw6ti9W7arApY8511POCwZw8tBuOHGQUTU9frC3IvA7\nOT53zQlYsPkAHp+70RRzLJkAAAr7SURBVPu8sq7ClU8vSHi/Tzfux6byaA+nVxYbsYneJYV4fO5G\nDOperLsUAHDPjFXICRAW//LsmPapG8377jhYg8LcoO0SEkUgCEKbsPiXZ9vbL98wAbWNsUVaOob1\nMALWV57YHyVFeZhkZsV065CPJ747zh5nFdpZvH7LKRjTzxlU7eThFvnjZceia1EeXloQW2ym0qtz\nAU4a0s3uqOrFnsrki+jUjKgZS3cBALbur8H9b671dX0owhj9m3e05yf+YQ6IgB+bizC1hmtIFIEg\nCDGoTe/8rPim0rko1zOI7KZX50I8f+0JGDugCw7XhWIUg8UPvzIUfzGzhV664UQ7lvH5L85CbUMY\npz0wx/O6+XedCQAYbLbkcPPq90/GJX//FID3EqHPTB6HR95fjzvOGWGvE+3GayW25vDKYqNdCLOh\ncApyAzENCFOBxAgEQWgzJo3ogU4FuVolAAC3nz0c6+47D1vu/6ojoF3aMd9RM/HgN0fj4jFGDcJ0\nM34BwG7VARir01kcdUS0keCcOychLxjAEZ0K8M/rT8SvLhyJM4/qiZm3TnTUYvzz+hNj5BtSGt8d\nlAx3/meZvf3igm3aNbBbGrEIBEFIa4jIM8/eYvYPT8W+w/U4bXgpLhnbBw99a4yjBUenglycPKQb\nThnaHfk5Qfz5W6MxsHuxox9SXk4Apwzthu4d8jFxWHdMdLXlePK7x6NrcR6OH9AFd51/JDbsPYz/\nmF/v9196LH47aw36dCnErOVlnjIu+uVZuH36Uny8fh8uGHUEZq/YHTOmpCg3psDtiM4FiX9BLQC1\nxSILRHQegEcABAE8zcz3xxs/btw4XrSo/SwULQhCevDUR5vQt0shzh/Vy26a5+7jpGPlzgps3leN\nC5VK6I/Xl6NTQS56dirAip0V2HagBlV1jfjRmcNQ0xDG/I37cdbInvjhy19g5rJdmHrhSHQqzMWs\n5WV4+PIxmP75dtw3aw0uGt0bq8sq8dINJ6JHx6YrAyJazMzjEo5rbUVAREEAXwI4G8AOAJ8D+A4z\nx9a9m4giEAShPbG3sg7PztuCO88Zbi9rChh1Cat2VeLo3p3sbqrNwa8iaIsYwXgAG5h5EzM3APgX\ngIvbQA5BEIQ2oUenAkw5/0iHEgAMN9gxfTq3iBJIhrZQBH0AqI1BdpjHHBDRjUS0iIgWlZeXt5pw\ngiAI2UbaZg0x85PMPI6Zx5WWlia+QBAEQWgSbaEIdgLop+z3NY8JgiAIbUBbKILPAQwjokFElAfg\ncgAz20AOQRAEAW1QR8DMISK6FcDbMNJHn2XmVa0thyAIgmDQJgVlzDwbwOy2eLYgCILgJG2DxYIg\nCELrIIpAEAQhy2mTFhPJQkTlAPQLmcanO4B9LShOqskkeTNJViCz5M0kWYHMkjeTZAWaJ+8AZk6Y\nf58RiqA5ENEiPyXW6UImyZtJsgKZJW8myQpklryZJCvQOvKKa0gQBCHLEUUgCIKQ5WSDIniyrQVI\nkkySN5NkBTJL3kySFcgseTNJVqAV5G33MQJBEAQhPtlgEQiCIAhxEEUgCIKQ5bRrRUBE5xHROiLa\nQERT0kCeZ4loLxGtVI51JaJ3iWi9+W8X8zgR0V9M2ZcT0dg2kLcfEc0hotVEtIqIfpSuMhNRAREt\nJKJlpqy/No8PIqIFpkzTzUaHIKJ8c3+DeX5ga8mqyBwkoi+I6I0MkHULEa0goqVEtMg8lnZ/B4q8\nJUT0ChGtJaI1RHRSOspLRCPM36n1U0lEt7W6rMzcLn9gNLTbCGAwgDwAywCMbGOZTgMwFsBK5dgf\nAUwxt6cA+IO5fQGANwEQgAkAFrSBvL0AjDW3O8JYYnRkOspsPrODuZ0LYIEpw78BXG4efxzAzeb2\n9wE8bm5fDmB6G/x+fwzgJQBvmPvpLOsWAN1dx9Lu70CR7QUA/2du5wEoSWd5TTmCAHYDGNDasrb6\ny7biL/UkAG8r+3cBuCsN5BroUgTrAPQyt3sBWGduPwFjLeeYcW0o+wwYa02ntcwAigAsAXAijIrM\nHPffBIzutyeZ2znmOGpFGfsCeB/AVwC8Yf6PnZayms/1UgRp+XcAoDOAze7fUbrKqzz3HADz2kLW\n9uwa8rUkZhrQk5nLzO3dAHqa22klv+mOOA7Gl3Zaymy6WpYC2AvgXRgW4SFmDnnIY8tqnq8A0K21\nZAXwMICfAoiY+92QvrICAAN4h4gWE9GN5rG0/DsAMAhAOYDnTNfb00RUjPSV1+JyAC+b260qa3tW\nBBkHGyo+7fJ5iagDgP8CuI2ZK9Vz6SQzM4eZeQyMr+3xAI5sY5E8IaKvAdjLzIvbWpYkmMjMYwGc\nD+AWIjpNPZlOfwcwrKaxAB5j5uMAVMNwr9ikmbww40EXAfiP+1xryNqeFUGmLIm5h4h6AYD5717z\neFrIT0S5MJTAi8z8qnk4rWVm5kMA5sBwr5QQkbXuhiqPLat5vjOA/a0k4ikALiKiLQD+BcM99Eia\nygoAYOad5r97AbwGQ9Gm69/BDgA7mHmBuf8KDMWQrvIChoJdwsx7zP1WlbU9K4JMWRJzJoDJ5vZk\nGH546/jVZpbABAAViqnYKhARAXgGwBpm/rNyKu1kJqJSIioxtwthxDLWwFAIl2lktd7hMgAfmF9e\nKYeZ72Lmvsw8EMbf5QfMfGU6ygoARFRMRB2tbRi+7JVIw78DAGDm3QC2E9EI89CZAFanq7wm30HU\nLWTJ1HqytnZApJWDLxfAyHTZCOAXaSDPywDKADTC+Gq5Hoav930A6wG8B6CrOZYA/M2UfQWAcW0g\n70QYJulyAEvNnwvSUWYAxwL4wpR1JYB7zOODASwEsAGG2Z1vHi8w9zeY5we30d/EJESzhtJSVlOu\nZebPKuv/pXT8O1BkHgNgkfn38DqALukqL4BiGBZeZ+VYq8oqLSYEQRCynPbsGhIEQRB8IIpAEAQh\nyxFFIAiCkOWIIhAEQchyRBEIgiBkOaIIhKyAiA6b/w4koita+N4/d+1/2pL3F4RUI4pAyDYGAkhK\nESjVvjocioCZT05SJkFoU0QRCNnG/QBONXu/3242qnuAiD43+7t/DwCIaBIRfUxEM2FUpYKIXjeb\nrq2yGq8R0f0ACs37vWges6wPMu+9koxe/t9W7v0hRfvlv2hWcYOI7idj/YflRPSnVv/tCFlJoi8d\nQWhvTAFwJzN/DQDMCb2CmU8gonwA84joHXPsWADHMPNmc/86Zj5gtrD4nIj+y8xTiOhWNprdubkE\nRoXraADdzWs+Ms8dB+BoALsAzANwChGtAfANAEcyM1stMwQh1YhFIGQ758Do3bIURovtbgCGmecW\nKkoAAH5IRMsAfAaj8dcwxGcigJfZ6Iq6B8BcACco997BzBEYrTsGwmgvXQfgGSK6BEBNs99OEHwg\nikDIdgjAD5h5jPkziJkti6DaHkQ0CcBZMBaIGQ2jr1FBM55br2yHYSxIE4LR1fMVAF8D8FYz7i8I\nvhFFIGQbVTCW3bR4G8DNZrttENFws8Omm84ADjJzDREdCWOZQItG63oXHwP4thmHKIWxVOlCnWDm\nug+dmXk2gNthuJQEIeVIjEDINpYDCJsunudhrAMwEMASM2BbDuDrHte9BeAm04+/DoZ7yOJJAMuJ\naAkb7aQtXoOxJsIyGF1cf8rMu01F4kVHADOIqACGpfLjpr2iICSHdB8VBEHIcsQ1JAiCkOWIIhAE\nQchyRBEIgiBkOaIIBEEQshxRBIIgCFmOKAJBEIQsRxSBIAhClvP/L5JP+B+rnp4AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "W [[-0.2282553   0.26556649  0.09247469 ... -0.04821143  0.24209406\n",
            "  -0.48798425]]\n",
            "b [[2.00964715]]\n",
            "Y [[-5.64782583]]\n",
            "B [[-1.85033131]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}